{"code":"(window.webpackJsonp=window.webpackJsonp||[]).push([[33],{318:function(s,t,a){\"use strict\";a.r(t);var n=a(7),e=Object(n.a)({},(function(){var s=this,t=s._self._c;return t(\"ContentSlotsDistributor\",{attrs:{\"slot-key\":s.$parent.slotKey}},[t(\"h1\",{attrs:{id:\"hashmap\"}},[t(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#hashmap\"}},[s._v(\"#\")]),s._v(\" HashMap\")]),s._v(\" \"),t(\"p\",[s._v(\"HashMap是基于hash算法的一个K-V结构存储的容器，不支持顺序读写，不支持并发操作。本文以1.8版本为例。\")]),s._v(\" \"),t(\"p\",[s._v(\"继承关系\\n\"),t(\"img\",{attrs:{src:\"/images/java_basics/collections/HashMap.png\",alt:\"继承关系\"}})]),s._v(\" \"),t(\"h2\",{attrs:{id:\"结构\"}},[t(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#结构\"}},[s._v(\"#\")]),s._v(\" 结构\")]),s._v(\" \"),t(\"p\",[s._v(\"JDK1.8的HashMap是由数组+链表+红黑树的数据结构实现的，如下图\")]),s._v(\" \"),t(\"p\",[t(\"img\",{attrs:{src:\"/images/java_basics/collections/1.8HashMap%E7%BB%93%E6%9E%84.png\",alt:\"结构\"}})]),s._v(\" \"),t(\"h2\",{attrs:{id:\"node源码\"}},[t(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#node源码\"}},[s._v(\"#\")]),s._v(\" Node源码\")]),s._v(\" \"),t(\"p\",[s._v(\"Node作为HashMap的静态内部类，是一个单向链表结构，用来存储存放数据。\")]),s._v(\" \"),t(\"div\",{staticClass:\"language-java line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-java\"}},[t(\"code\",[t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"static\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"class\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Node\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"implements\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Map\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"Entry\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"final\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"int\")]),s._v(\" hash\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"//数组索引下标\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"final\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),s._v(\" key\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),s._v(\" value\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Node\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),s._v(\" next\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"//只有next，代表是一个单向链表\")]),s._v(\"\\n\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Node\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"int\")]),s._v(\" hash\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),s._v(\" key\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),s._v(\" value\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Node\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),s._v(\" next\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"this\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"hash \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" hash\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"this\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"key \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" key\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"this\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"value \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" value\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"this\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"next \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" next\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"public\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"final\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"getKey\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"        \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"return\")]),s._v(\" key\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"public\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"final\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"getValue\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"      \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"return\")]),s._v(\" value\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"public\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"final\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"String\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"toString\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"return\")]),s._v(\" key \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"+\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v('\"=\"')]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"+\")]),s._v(\" value\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"public\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"final\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"int\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"hashCode\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"public\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"final\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"setValue\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),s._v(\" newValue\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"public\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"final\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"boolean\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"equals\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Object\")]),s._v(\" o\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"5\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"6\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"7\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"8\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"9\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"10\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"11\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"12\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"13\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"14\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"15\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"16\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"17\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"18\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"19\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"20\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"21\")]),t(\"br\")])]),t(\"h2\",{attrs:{id:\"hashmap属性\"}},[t(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#hashmap属性\"}},[s._v(\"#\")]),s._v(\" HashMap属性\")]),s._v(\" \"),t(\"div\",{staticClass:\"language-java line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-java\"}},[t(\"code\",[t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"/**\\n * 数组，在第一次put时初始化，并根据当前容量进行调整，该数组的长度必须时2的次幂\\n * 默认值为 static final int DEFAULT_INITIAL_CAPACITY = 1 << 4;\\n */\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"transient\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Node\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),s._v(\" table\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"/**\\n * 存储 K-V 数据的个数，即 Node 对象的个数\\n */\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"transient\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"int\")]),s._v(\" size\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"/**\\n * 用来记录HashMap内部结构发生变化的次数\\n *\\n * This field is used to make iterators on Collection-views of the HashMap fail-fast.\\n * 用于迭代的快速失败\\n */\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"transient\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"int\")]),s._v(\" modCount\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"/**\\n * 记录HashMap中达到负载的Node个数，当达到这个值之后，开始执行扩容\\n * 计算方法： capacity * load factor\\n */\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"int\")]),s._v(\" threshold\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"/**\\n * 负载因子，初始化容器时如果不指定，则使用 DEFAULT_LOAD_FACTOR\\n */\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"final\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"float\")]),s._v(\" loadFactor\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"5\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"6\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"7\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"8\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"9\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"10\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"11\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"12\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"13\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"14\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"15\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"16\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"17\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"18\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"19\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"20\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"21\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"22\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"23\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"24\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"25\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"26\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"27\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"28\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"29\")]),t(\"br\")])]),t(\"h2\",{attrs:{id:\"主要方法\"}},[t(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#主要方法\"}},[s._v(\"#\")]),s._v(\" 主要方法\")]),s._v(\" \"),t(\"h3\",{attrs:{id:\"_1-hash方法-确定key在table中的数组下标\"}},[t(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_1-hash方法-确定key在table中的数组下标\"}},[s._v(\"#\")]),s._v(\" 1. hash方法：确定key在table中的数组下标\")]),s._v(\" \"),t(\"p\",[s._v(\"HashMap无论时在增、删、查的过程中都需要对key进行hash运算，定位到对应的哈希桶后再进行后续操作，所以hash方法很关键\")]),s._v(\" \"),t(\"div\",{staticClass:\"language-java line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-java\"}},[t(\"code\",[t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"static\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"final\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"int\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"hash\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Object\")]),s._v(\" key\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"int\")]),s._v(\" h\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"//key == null 代表这里的key可以为null\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// h = key.hashCode() \")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 1. 先对key进行hash计算得到h\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 2. 得到的结果h再右移16位 \")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// 1和2 两步得到的结果异或运算最终的到数组位置下标\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"return\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"key \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"==\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"?\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\":\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"h \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" key\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"hashCode\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"^\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"h \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\">>>\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"16\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"5\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"6\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"7\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"8\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"9\")]),t(\"br\")])]),t(\"p\",[s._v(\"如下图，n=16\\n\"),t(\"img\",{attrs:{src:\"/images/java_basics/collections/hash%E8%AE%A1%E7%AE%97.png\",alt:\"hash计算\"}})]),s._v(\" \"),t(\"ul\",[t(\"li\",[t(\"p\",[s._v(\"为什么JDK1.8要用这种方式计算hash？\")]),s._v(\" \"),t(\"p\",[s._v(\"是为了尽可能的将hash值散列到各个哈希桶中，利用高16位和低16位都参与到hash运算中，在保证性能的前提下，使计算结果分布的更均匀。\")])])]),s._v(\" \"),t(\"h3\",{attrs:{id:\"_2-put方法\"}},[t(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_2-put方法\"}},[s._v(\"#\")]),s._v(\" 2. put方法\")]),s._v(\" \"),t(\"div\",{staticClass:\"language-java line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-java\"}},[t(\"code\",[t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"final\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"putVal\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"int\")]),s._v(\" hash\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),s._v(\" key\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),s._v(\" value\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"boolean\")]),s._v(\" onlyIfAbsent\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"boolean\")]),s._v(\" evict\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Node\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),s._v(\" tab\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Node\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),s._v(\" p\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"int\")]),s._v(\" n\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" i\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"tab \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" table\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"==\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"||\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"n \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" tab\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"length\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"==\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"//如果数组为空,直接扩容，如果是第一次添加元素，则resize内部是初始化table等属性的过程\")]),s._v(\"\\n        n \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"tab \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"resize\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"length\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"p \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" tab\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),s._v(\"i \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"n \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"-\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"&\")]),s._v(\" hash\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"==\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"//tab[i = (n - 1) & hash] 计算出数组下标，如果下标位置的头节点为空，则为该下标new一个新节点作为头节点\")]),s._v(\"\\n        tab\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),s._v(\"i\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"newNode\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"hash\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" key\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" value\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"else\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"//如果下标位置的头节点不为空\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Node\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),s._v(\" e\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),s._v(\" k\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"//p代表下标位置的头节点\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"p\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"hash \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"==\")]),s._v(\" hash \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"&&\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"k \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" p\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"key\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"==\")]),s._v(\" key \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"||\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"key \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"!=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"&&\")]),s._v(\" key\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"equals\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"k\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"//如果头节点的key和要插入的key相同，说明插入了重复的key\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"//直接复用头节点的Node对象，key不变，value进行覆盖即可(覆盖的操作在后面)\")]),s._v(\"\\n            e \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" p\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"else\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"p \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"instanceof\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"TreeNode\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"//如果头节点为红黑树，直接调用红黑树的插入方法新增节点即可\")]),s._v(\"\\n            e \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"TreeNode\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"p\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"putTreeVal\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"this\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" tab\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" hash\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" key\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" value\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"else\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"//这里就时遍历链表，进行尾插\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"for\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"int\")]),s._v(\" binCount \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"++\")]),s._v(\"binCount\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n                \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"e \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" p\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"next\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"==\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n                    \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"//尾插法，将新构建的Node放在链表尾端\")]),s._v(\"\\n                    p\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"next \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"newNode\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"hash\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" key\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" value\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n                    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"binCount \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\">=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[s._v(\"TREEIFY_THRESHOLD\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"-\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// -1 for 1st\")]),s._v(\"\\n                        \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"//这里判断链表节点数量如果大于等于7(还没有++，其实已经是8个节点了)，转换成红黑树\")]),s._v(\"\\n                        \"),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"treeifyBin\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"tab\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" hash\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n                    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"break\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n                \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n                \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"e\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"hash \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"==\")]),s._v(\" hash \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"&&\")]),s._v(\"\\n                    \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"k \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" e\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"key\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"==\")]),s._v(\" key \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"||\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"key \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"!=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"&&\")]),s._v(\" key\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"equals\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"k\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n                    \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"//这里和头节点判断相同，判断key是否重复，如果重复在后面的代码中进行value的覆盖操作\")]),s._v(\"\\n                    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"break\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n                \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n                p \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" e\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"//遍历到这里，p的指针指向链表最尾端的节点对象\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"e \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"!=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// existing mapping for key\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),s._v(\" oldValue \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" e\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"value\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"!\")]),s._v(\"onlyIfAbsent \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"||\")]),s._v(\" oldValue \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"==\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n                \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"//覆盖value\")]),s._v(\"\\n                e\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"value \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" value\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"afterNodeAccess\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"e\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"return\")]),s._v(\" oldValue\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"++\")]),s._v(\"modCount\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"//操作数+1\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"++\")]),s._v(\"size \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\">\")]),s._v(\" threshold\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"//如果当前HashMap中的节点数>阈值(容器容量*负载因子)，则进行扩容操作\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"resize\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"afterNodeInsertion\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"evict\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"return\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"5\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"6\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"7\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"8\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"9\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"10\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"11\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"12\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"13\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"14\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"15\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"16\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"17\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"18\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"19\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"20\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"21\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"22\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"23\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"24\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"25\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"26\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"27\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"28\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"29\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"30\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"31\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"32\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"33\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"34\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"35\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"36\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"37\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"38\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"39\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"40\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"41\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"42\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"43\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"44\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"45\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"46\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"47\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"48\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"49\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"50\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"51\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"52\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"53\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"54\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"55\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"56\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"57\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"58\")]),t(\"br\")])]),t(\"h3\",{attrs:{id:\"resize方法-扩容\"}},[t(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#resize方法-扩容\"}},[s._v(\"#\")]),s._v(\" resize方法：扩容\")]),s._v(\" \"),t(\"div\",{staticClass:\"language-java line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-java\"}},[t(\"code\",[t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"final\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Node\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"resize\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Node\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),s._v(\" oldTab \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" table\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"int\")]),s._v(\" oldCap \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"oldTab \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"==\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"?\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\":\")]),s._v(\" oldTab\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"length\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"int\")]),s._v(\" oldThr \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" threshold\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"int\")]),s._v(\" newCap\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" newThr \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"oldCap \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\">\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// oldCap > 0 代表原先已经有元素了，在插入之后进行扩容的场景\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"oldCap \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\">=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[s._v(\"MAXIMUM_CAPACITY\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"//达到允许的最大值 2^30, 将阈值设置为int最大值2^31-1, 就不再扩容了\")]),s._v(\"\\n            threshold \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Integer\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[s._v(\"MAX_VALUE\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"return\")]),s._v(\" oldTab\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"else\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"newCap \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" oldCap \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"<<\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"<\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[s._v(\"MAXIMUM_CAPACITY\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"&&\")]),s._v(\"\\n                 oldCap \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\">=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[s._v(\"DEFAULT_INITIAL_CAPACITY\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"//这里左移1位，就是两倍扩容\")]),s._v(\"\\n            newThr \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" oldThr \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"<<\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// double threshold\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"else\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"oldThr \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\">\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// initial capacity was placed in threshold\")]),s._v(\"\\n        newCap \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" oldThr\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"else\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"               \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// zero initial threshold signifies using defaults\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"//这个else 代表是第一次put元素时，初始化容器中的一些默认值\")]),s._v(\"\\n        newCap \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[s._v(\"DEFAULT_INITIAL_CAPACITY\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n        newThr \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"int\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[s._v(\"DEFAULT_LOAD_FACTOR\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"*\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[s._v(\"DEFAULT_INITIAL_CAPACITY\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"newThr \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"==\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"//重新计算容器阈值\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"float\")]),s._v(\" ft \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"float\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"newCap \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"*\")]),s._v(\" loadFactor\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n        newThr \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"newCap \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"<\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[s._v(\"MAXIMUM_CAPACITY\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"&&\")]),s._v(\" ft \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"<\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"float\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[s._v(\"MAXIMUM_CAPACITY\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"?\")]),s._v(\"\\n                  \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"int\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"ft \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\":\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Integer\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token constant\"}},[s._v(\"MAX_VALUE\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n    threshold \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" newThr\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token annotation punctuation\"}},[s._v(\"@SuppressWarnings\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v('\"rawtypes\"')]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v('\"unchecked\"')]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Node\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),s._v(\" newTab \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Node\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"new\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Node\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),s._v(\"newCap\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"//初始化一个新的数组，准备开始移动元素\")]),s._v(\"\\n    table \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" newTab\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"oldTab \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"!=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"for\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"int\")]),s._v(\" j \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\" j \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"<\")]),s._v(\" oldCap\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"++\")]),s._v(\"j\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"//遍历旧的数组元素\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Node\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),s._v(\" e\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"e \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" oldTab\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),s._v(\"j\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"!=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n                oldTab\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),s._v(\"j\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n                \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"e\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"next \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"==\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n                    \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"//这里按照新的数组大小和hash值进行与运算得到新数组中的下标\")]),s._v(\"\\n                    newTab\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),s._v(\"e\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"hash \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"&\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"newCap \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"-\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"1\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" e\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n                \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"else\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"e \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"instanceof\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"TreeNode\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n                    \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"//红黑树和链表的转换\")]),s._v(\"\\n                    \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"TreeNode\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"e\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"split\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"this\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" newTab\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" j\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" oldCap\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n                \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n                \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"else\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"// preserve order\")]),s._v(\"\\n                    \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Node\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),s._v(\" loHead \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" loTail \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n                    \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Node\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),s._v(\" hiHead \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" hiTail \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n                    \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"Node\")]),t(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"<\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"K\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"V\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\">\")])]),s._v(\" next\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n                    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"do\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n                        next \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" e\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"next\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n                        \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"e\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"hash \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"&\")]),s._v(\" oldCap\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"==\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token number\"}},[s._v(\"0\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n                            \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"loTail \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"==\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n                                loHead \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" e\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n                            \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"else\")]),s._v(\"\\n                                loTail\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"next \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" e\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n                            loTail \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" e\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n                        \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n                        \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"else\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n                            \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"hiTail \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"==\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\"\\n                                hiHead \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" e\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n                            \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"else\")]),s._v(\"\\n                                hiTail\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"next \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" e\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n                            hiTail \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" e\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n                        \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n                    \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"while\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"e \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" next\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"!=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n                    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"loTail \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"!=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n                        loTail\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"next \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n                        newTab\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),s._v(\"j\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" loHead\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n                    \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n                    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"if\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"hiTail \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"!=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"{\")]),s._v(\"\\n                        hiTail\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"next \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"null\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n                        newTab\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),s._v(\"j \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"+\")]),s._v(\" oldCap\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" hiHead\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n                    \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n                \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n            \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"return\")]),s._v(\" newTab\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\";\")]),s._v(\"\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"}\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"5\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"6\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"7\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"8\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"9\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"10\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"11\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"12\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"13\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"14\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"15\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"16\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"17\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"18\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"19\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"20\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"21\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"22\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"23\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"24\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"25\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"26\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"27\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"28\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"29\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"30\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"31\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"32\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"33\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"34\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"35\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"36\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"37\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"38\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"39\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"40\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"41\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"42\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"43\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"44\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"45\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"46\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"47\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"48\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"49\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"50\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"51\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"52\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"53\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"54\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"55\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"56\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"57\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"58\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"59\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"60\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"61\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"62\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"63\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"64\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"65\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"66\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"67\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"68\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"69\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"70\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"71\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"72\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"73\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"74\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"75\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"76\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"77\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"78\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"79\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"80\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"81\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"82\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"83\")]),t(\"br\")])])])}),[],!1,null,null,null);t.default=e.exports}}]);","extractedComments":[]}